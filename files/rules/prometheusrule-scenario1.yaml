apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: scenario1-rules
  namespace: monitoring
  labels:
    release: kps
    scenario: "1"
spec:
  groups:
    - name: scenario1.rules
      rules:

        # ============================================================
        # ðŸ§  NODE STATUS & CLUSTER HEALTH
        # ============================================================

        - record: scenario1:node_ready
          expr: count(kube_node_status_condition{condition="Ready", status="true"})
          labels: { category: node }

        - record: scenario1:node_not_ready
          expr: count(kube_node_status_condition{condition="Ready", status!="true"})
          labels: { category: node }

        # ============================================================
        # âš™ï¸ HPA (Horizontal Pod Autoscaler) METRICS
        # ============================================================

        - record: scenario1:hpa_desired
          expr: sum(kube_horizontalpodautoscaler_status_desired_replicas)
          labels: { category: hpa }

        - record: scenario1:hpa_current
          expr: sum(kube_horizontalpodautoscaler_status_current_replicas)
          labels: { category: hpa }

        # ============================================================
        # ðŸ§© POD DEPLOYMENT STATUS
        # ============================================================

        - record: scenario1:pod_desired
          expr: sum(kube_deployment_spec_replicas)
          labels: { category: pod }

        - record: scenario1:pod_ready
          expr: sum(kube_deployment_status_replicas_ready)
          labels: { category: pod }

        - record: scenario1:pod_pending
          expr: sum(kube_pod_status_phase{phase="Pending"})
          labels: { category: pod }

        # ============================================================
        # ðŸ”‹ RESOURCE UTILIZATION (CPU / MEMORY)
        # ============================================================

        - record: scenario1:cpu_usage_cores
          expr: sum(rate(container_cpu_usage_seconds_total{image!=""}[1m]))
          labels: { unit: cores, category: resource }

        - record: scenario1:mem_working_set_gb
          expr: sum(container_memory_working_set_bytes{image!=""}) / 1024 / 1024 / 1024
          labels: { unit: gigabytes, category: resource }

        - record: scenario1:cpu_usage_namespace
          expr: |
            sum by (namespace) (
              rate(container_cpu_usage_seconds_total{container!="",namespace!~"kube-system|monitoring"}[1m])
            )
          labels: { category: namespace }

        - record: scenario1:mem_usage_namespace
          expr: |
            sum by (namespace) (
              container_memory_working_set_bytes{container!="",namespace!~"kube-system|monitoring"}
            ) / 1024 / 1024 / 1024
          labels: { category: namespace }

        # ============================================================
        # ðŸš€ CLUSTER AUTOSCALER EVENTS
        # ============================================================

        - alert: ClusterAutoscalerScaledUp
          expr: increase(cluster_autoscaler_scaled_up_nodes_total[5m]) > 0
          for: 1m
          labels: { severity: warning, category: autoscaler }
          annotations:
            summary: "Cluster Autoscaler scaled up nodes"
            description: "Detected new nodes added by CA in the last 5 minutes."

        - alert: ClusterAutoscalerScaledDown
          expr: increase(cluster_autoscaler_scaled_down_nodes_total[5m]) > 0
          for: 1m
          labels: { severity: info, category: autoscaler }
          annotations:
            summary: "Cluster Autoscaler scaled down nodes"
            description: "Detected nodes removed by CA in the last 5 minutes."

        # ============================================================
        # ðŸ§¯ HPA SCALING ALERTS & LATENCY
        # ============================================================

        - alert: HPAScalingUp
          expr: increase(kube_horizontalpodautoscaler_status_current_replicas[5m]) > 0
          for: 1m
          labels: { severity: info, category: hpa }
          annotations:
            summary: "HPA scaled up workload"
            description: "Detected increase in pod replicas by HPA within 5 minutes."

        - alert: HPAScalingDown
          expr: increase(kube_horizontalpodautoscaler_status_current_replicas[5m]) < 0
          for: 1m
          labels: { severity: info, category: hpa }
          annotations:
            summary: "HPA scaled down workload"
            description: "Detected decrease in pod replicas by HPA within 5 minutes."

        - alert: ScalingLatencyHigh
          expr: increase(kube_pod_status_phase{phase="Pending"}[5m]) > 5
          for: 5m
          labels: { severity: warning, category: latency }
          annotations:
            summary: "Scaling latency cao"
            description: "Pod má»›i máº¥t >5 phÃºt Ä‘á»ƒ chuyá»ƒn tá»« Pending sang Running â€“ scale-out cháº­m."
